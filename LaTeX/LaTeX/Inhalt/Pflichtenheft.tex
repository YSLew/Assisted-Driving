\chapter{Pflichtenheft}
\label{cha:Pflichtenheft}

% ----------------------------------------------------------------------------------------------------------
% Section
% ----------------------------------------------------------------------------------------------------------
\section{Projektziel/Einführung}

Ziel des Projekts ist es ein System zu entwickeln, welches in der Lage ist (Vorfahrts-) Schilder im Straßenverkehr autonom zu erfassen. Die Erfassung erfolgt ? während der Fahrt ? mit Hilfe einer Kamera. Ist das System aktiv, läuft die Kamera stets mit und es werden alle erfassten Bilder in die zentrale Recheneinheit (CPU) weitergeleitet. Dort werden diese mittels einer Bilderfassungssoftware analysiert und die Informationen der erkannten Verkehrsschilder an den Fahrer weitergeleitet. Die Ausgabe erfolgt visuell; auf einem Display wird das erfasste (Vorfahrts-) Schild durch ein Icon dargestellt. 

\vspace{1em}
\begin{minipage}{\linewidth}
	\centering
	\includegraphics[width=0.7\linewidth]{Bilder/Einfuehrung_Bild.png}
	\captionof{figure}[Modell]{Modell}
	\label{fig:Einfuehrung_Bild}
\end{minipage}

\section{Anforderungsanalyse}

\subsection{Muss-Anforderungen}

Die hier beschriebenen Punkte müssen erfüllt werden, um das Projekt erfolgreich abzuschließen.

\begin{enumerate}
\item Es werden mindestens zwei deutsche Vorfahrtsschilder (Stopp-Schild und ?Vorfahrt beachten?) korrekt erkannt.
\item 51\% aller Schilder werden korrekt erkannt. 
\item Die Bilderfassung erfolgt korrekt (siehe M2) bis zu einer Fahrzeuggeschwindigkeit von 30 km/h. 
\item Die Bilderfassung erfolgt mit einer Abtastrate von mindestens 1 Hz (max. möglicher Schilder-Abstand dadurch ca. 10m bei 30 km/h).
\item Die von der Kamera aufgenommenen Bilder werden in eine niedrigere Auflösung umgerechnet. Diese und die maximal mögliche Auflösung der aufgenommenen Bilder sind zu bestimmen (unter Beachtung von M2 und M4).
\item Die Ausgabe des erkannten Zeichens erfolgt über eine LED (eine je erkanntes Schild) nach maximal 1 Sekunde.
\end{enumerate}

\subsection{Soll-Anforderungen}

Die folgenden Anforderungen sollen umgesetzt werden. Sie sind fest in den Projektplan integriert, sind jedoch nicht projektentscheidend. 

\begin{enumerate}
\item Es werden alle deutschen Vorfahrtszeichen korrekt erkannt.
\item Die Bilderfassung erfolgt korrekt (siehe M2) bis zu einer Fahrzeuggeschwindigkeit von 60 km/h. 
\item Die Bilderfassung erfolgt mit einer Abtastrate von mindestens 2 Hz (max. möglicher Schilder-Abstand dadurch ca. 10m bei 60 km/h).
\item Die Geschwindigkeit des Fahrzeuges, in dem das System verbaut wird, soll über ein CAN-Bus-System erfasst werden. Bei der Überschreitung von 60 km/h soll eine Warnung ausgegeben werden. 
\item Die Anzeige des erkannten Zeichens soll über ein Display erfolgen, in welchem das erkannte Verkehrszeichen abgebildet wird (nach max. 0,5 Sekunden), das Icon erscheint 15 s oder bis zur Erkennung eines neuen Verkehrszeichens.
\end{enumerate}

\subsection{Kann-Anforderungen}

Die folgenden Anforderungen sind optional und können im Laufe des Projektes erreicht werden, bzw. dienen als Ausgangspunkt für mögliche Erweiterungen. Sie sind nicht notwendig, um das Projekt zu einem erfolgreichen Abschluss zu führen.

\begin{enumerate}
\item Das System kann weitere  Verkehrsschilder erkennen. 
\item Die Bilderfassung wird mit einem Smartphone durchgeführt, welches vom Nutzer gestellt wird.
\item Die erkannten Verkehrszeichen werden über ein HUD (Head-up-Display) in die Windschutzscheibe in den Sichtbereich des Fahrers projiziert. 
\item Zusätzlich zur Anzeige wird ein akustischer Warnton ausgelöst, wenn z.B. ein Stoppschild ohne Anhalten überfahren wurde.
\item Durch Erweiterung auf eine Car-2-Car Communication (WLAN- und GPS-basiert) wird vor einem bevorstehenden Unfall gewarnt, andere Verkehrsteilnehmer in der Nähe werden z.B. bei überfahrenen Stopp-Schildern gewarnt und ggf. automatisch gebremst.
\end{enumerate}

\section{Entwicklungstools}

Die zu entwerfende Software wird mit Hilfe der Entwicklungsumgebung ''{}Visual Studio 2013''{} \footnote{\url{https://www.visualstudio.com/} \\letzter Zugriff: 25.10.2015} entworfen, unter Nutzung der Open-Source-Bibliothek ''{}OpenCV''{} \footnote{\url{http://opencv.org/} \\letzter Zugriff: 25.10.2015}. Das fertige System soll auf einer für diese Anwendung optimierten und mit dem Build-Werkzeug ''{}yocto''{} \footnote{\url{https://www.yoctoproject.org/} \\letzter Zugriff: 25.10.2015} erstellten Linux-Distribution in Betrieb genommen werden. Für deren Start- und Flashvorgang auf der gewählten Hardware kommt der Open-Source-Bootloader ''{}U-Boot''{} \footnote{\url{http://www.denx.de/wiki/U-Boot/WebHome} \\letzter Zugriff: 25.10.2015} zum Einsatz. 

\section{Hauptkomponenten}

\subsection{Algorithmischer Ansatz}

Die von der Kamera erfassten Bilder werden unter Verwendung geeigneter Filter-Algorithmen vorbearbeitet und skaliert. Anschließend durchlaufen die nun erhaltenen Daten einen für die einzelnen Verkehrszeichen spezifischen Farbfilter. Daraufhin können geeignete Objekterkennende Algorithmen (Feature-Tracking und ggf. Viola-Jones) genutzt werden, um die gewünschten Schilder eindeutig zu identifizieren. Die genutzten Algorithmen werden so gewählt, dass auch nur teilweise erkennbare sowie farblich variierende Zeichen (z.B. bei unterschiedlichen Lichtstimmungen) erkannt werden können und dabei gleichzeitig ausreichend Performance garantieren.

\subsection{Hardware}

Die fertig entwickelten Programme werden auf ein ?MarS-Board? der Firma Embest Technologies überspielt. Dieses stellt neben einem ausreichend schnellen ARM Cortex-A9-Prozessor und zwei USB-Schnittstellen an denen direkt die benötigte Kamera angebunden werden kann, auch einen speziellen Grafikprozessor (Vivante GC2000) der zur Vorverarbeitung der eingehende Bilder genutzt werden kann. Eine Ethernet-Schnittstelle erlaubt ebenfalls den Zugriff auf Kameras über ein Netzwerk.

\subsection{Kamera}

Verwendet wird die USB3.0-Kamera mxBlueFox3 der Firma Matrix Vision. Diese bietet mit 10 Megapixel ein Vielfaches der geforderten Auflösung und steht im Labor der HTW zur Verfügung.


\section{Probleme}

\subsection{Potentielle Probleme im Entwicklungsprozess}

Größte Herausforderung im Entwicklungsprozess wird die Anpassung der gewählten Algorithmen sein, so dass diese einen akzeptablen Kompromiss zwischen Performance (maximale Bildübertragungsrate bei gewünschter Auflösung) und Erfolgsrate der Objekterkennung bietet. Es ist zu untersuchen unter welchen Bedingungen das System noch einwandfrei arbeitet und welche Verkehrszeichen besonders schwierig zu erkennen sind. Die folgende Optimierung des Codes wird aufgrund der Komplexität der Bildverarbeitenden Algorithmen viel Zeit in Anspruch nehmen.

\subsection{Externe Einflüsse im Betrieb}

Das finale System wird stets nur eine begrenzte Erfolgsquote bei der Erkennung der Verkehrszeichen aufweisen. Im Straßenverkehr können Schilder verdreht oder verdreckt sein und je nach Tageszeit und Wetter unterschiedlich schwer wahr zu nehmen sein. Ziel muss es sein, diese Störeinflüsse zu identifizieren und klare Regeln zu definieren, unter denen das System noch einwandfrei arbeitet.


\section{Ablaufplan}

\vspace{1em}
\begin{minipage}{\linewidth}
	\centering
	\includegraphics[width=1\linewidth]{Bilder/Ablaufplan.png}
	\captionof{figure}[Ablaufplan]{Ablaufplan}
	\label{fig:Ablaufplan}
\end{minipage}


\section{Phasenplan}

\begin{table}[h]
\centering
\begin{tabular}{lll}
	\hline
	\textbf{Phase} & \textbf{Ziel/Meilenstein} & \textbf{Zeitraum} \\
	\hline
	Recherche & Lastenheft & 25.04.15 - 04.05.15 \\
	Konzeptphase & Pflichtenheft & 28.04.15 - 18.06.15 \\
	Entwurfsphase & Fertigstellung Algorithmen & 05.06.15 - 03.07.15 \\
	Fertigungsphase & Lauffähiges System & 25.06.15 - 11.12.15 \\
	Betriebsphase & Abgeschlossenes Projekt & 13.11.15 - 07.01.16 \\
	Präsentationsphase & Abgabe Projekt & 21.05.15 - 11.02.16 \\
	\hline
\end{tabular}
\caption{Phasenplan}
\label{tab:Phasenplan}
\end{table}

Der Phasenplan des Projektes besteht insgesamt aus sieben Phasen. Diese Phasen besitzen teils einen fließend zeitlichen Übergang zueinander. 

Zuerst erfolgt in der Recherchephase (April bis Mai 2015) das Vertraut-Machen der Projektmitglieder mit der Entwicklungsumgebung "Microsoft Visual Studio" in Kombination mit den OpenCV Bibliotheken. Außerdem werden die Anforderungen (Spezifikationen) an das Projekt definiert; das Lastenheft entsteht. 

Zeitlich versetzt zur Recherchephase erfolgt bereits die Konzeptphase (April bis Juni 2015), die in dem Pflichtenheft endet. Die Projektanforderungen aus dem Lastenheft werden validiert und es erfolgt eine Aufschlüsselung nach Muss-, Soll-, und Kann-Kriterien hinsichtlich Umsetzbarkeit. Ebenso wird nach diesen Kriterien die Hard- und Software abgeleitet sowie ein erster algorithmischer Ansatz zur Problemlösung erstellt.

Von Juni bis Juli 2015 verläuft die Entwurfsphase. Hierin informieren sich die Projektteilnehmer über die Algorithmik zur Objekterkennung. Erste Testmuster zur Detektierung bestimmter Bildausschnitte werden erstellt. Diese Vorabuntersuchung erfolgt zunächst unabhängig von der später zu verwendenden Hardware.

In der Ende Juni 2015 startenden Fertigungsphase erfolgt zunächst die Beschaffung der Hardware, deren anschließende Inbetriebnahme (Schaffung Softwarebasis Mars-Board) sowie die Code-Implementierung. Ist die Fertigungsphase abgeschlossen, ist der Meilenstein "{}lauffähiges System"{} erreicht (Dezember 2015).

Die im November 2015 beginnende Betriebsphase umfasst die Implementierung des Gesamtsystems in der Fahrzeugumgebung. Praktische Tests werden durchgeführt sowie eventuelle softwaretechnische Fehler behoben. Im Januar 2016 ist der Abschluss der Betriebsphase geplant.

Die Präsentationsphase erfolgt parallel zu allen anderen erwähnten Phasen. Es erfolgen hierbei die Präsentationen zu den Zwischenständen, finalen Abschlüssen des Projektes und das Pflegen der Dokumentation. Die Präsentationsphase endet im Februar 2016 mit der Projektabgabe.
